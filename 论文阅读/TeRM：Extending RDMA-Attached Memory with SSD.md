---
title: TeRM：Extending RDMA-Attached Memory with SSD
categories:
  - 论文阅读
abbrlink: 2d325f6a
date: 2024-11-12 18:25:00
updated: 2024-11-12 20:05:00
---

<meta name="referrer" content="no-referrer"/>

原文地址：[https://www.usenix.org/conference/fast24/presentation/yang-zhe](https://www.usenix.org/conference/fast24/presentation/yang-zhe)

这篇论文提出了一种名为 TeRM 的系统，旨在通过 SSD 扩展 RDMA（远程直接内存访问）附加内存，以应对数据中心内存资源有限的问题。TeRM 通过软件化处理页面错误、分层 I/O 和动态热点提升等技术，减少了 CPU 和网络开销，提升了内存扩展的效率。

<!-- more -->

# 背景

1. RDMA（远程内存直接访问）

RDMA 是一种网络通信技术，允许客户端直接访问服务器端的内存，无需通过服务器的 CPU 处理，从而实现了非常低的延迟和高效的性能。相比传统的 TCP/IP 网络，RDMA 避免了数据在 CPU 和内存之间的多次传输，减少了延迟。因此，RDMA 非常适用于高性能的内存系统，如分布式文件系统、键值存储和事务性数据库。

尽管 RDMA 能够带来高性能，但数据中心的内存资源昂贵且有限。因此，仅依赖内存来满足存储需求并不实际。这一局限性促使研究人员寻找其他方式，例如通过 SSD 来扩展 RDMA 内存，使得这些系统能够处理超过物理内存容量的数据集。

2. ODP（按需分页）

ODP 通过硬件支持来扩展 RDMA 内存，其工作原理是当 RDMA 访问存储在 SSD 上的数据时，触发页面错误（page fault），然后由 CPU 从 SSD 中读取数据并更新 RNIC（RDMA 网络接口卡）的页面表。

ODP 的一个关键问题在于其页面错误处理效率低下。当页面错误发生时，RNIC 会停止队列并通知客户端的 RNIC 重新传输请求，这种方式耗时且增加了系统负担。实验表明，当从内存中访问数据时，ODP 的延迟仅为 3.66 微秒，但当数据在 SSD 上时，延迟会剧增到 570.74 微秒。ODP 的低效主要源于 RNIC 硬件资源有限，处理页面错误的能力不足。这样就导致 ODP 在扩展 RDMA 内存时并不理想。

# 设计与核心技术

TeRM 主要通过三大技术突破解决了现有系统的不足。

1. 将页面错误处理从硬件移到软件（软件化异常处理）

硬件的页面错误处理效率低下，因此 TeRM 将处理页面错误的任务从 RNIC 硬件转移到软件。这样避免了硬件在页面错误上的低效操作，从而加速了 SSD 数据的远程访问。

TeRM 为存储在 SSD 上的所有页面创建了一个“魔法页面”，RNIC 页面表中的无效页面被统一映射到该“魔法页面”。当客户端访问无效页面时，RNIC 会返回“魔法页面”的数据而不会触发硬件页面错误。然后，客户端通过 RPC（远程过程调用）从服务器获取 SSD 上的数据。这种方法消除了 RNIC 页面错误带来的延迟。

2. 分层 I/O（Tiering I/O）

直接在虚拟内存与 SSD 之间进行 I/O 操作会触发 CPU 页面错误，影响系统性能。为了消除这种问题，TeRM 使用分层 I/O，根据数据是否在物理内存中选择不同的 I/O 方式。关键思想是通过文件 I/O 接口而非内存加载/存储接口访问 SSD 扩展的虚拟内存。

分层 I/O 根据页面的状态采用不同的 I/O 方式：当数据已被缓存（缓冲 I/O），则可以快速访问；而当数据未缓存时，通过直接 I/O 绕过页面缓存来避免页面替换的开销。分层 I/O 有效地利用了内存中缓存的数据，提高了访问效率；对于存储在 SSD 中的数据，通过直接 I/O 降低了 CPU 的页面错误开销。

3. 动态热点提升（Dynamic Hotspot Promotion）

在实际应用中，某些数据会频繁访问（热点数据），而 TeRM 会将热点数据优先放置在物理内存中，以降低 SSD 访问的延迟。

TeRM 通过在客户端跟踪数据访问频率并在服务器端聚合这些数据来确定热点区域。然后，它会将热点数据动态地从 SSD 提升到物理内存中，使后续访问更加高效。这种设计确保了系统在不同访问模式下的灵活性，减少了热点数据在 SSD 上的访问延迟。

